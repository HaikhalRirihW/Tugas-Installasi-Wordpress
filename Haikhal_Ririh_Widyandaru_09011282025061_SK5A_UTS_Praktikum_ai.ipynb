{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HaikhalRirihW/Tugas-Installasi-Wordpress/blob/main/Haikhal_Ririh_Widyandaru_09011282025061_SK5A_UTS_Praktikum_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44JRqlK3IyFv"
      },
      "source": [
        "Deteksi Masker Pada Muka Menggunakan Teknik Deep Learning\n",
        "\n",
        "09011282025061_Haikhal Ririh Widyandaru\n",
        "\n",
        "Project UTS Praktikum Kecerdasan Buatan Program Machine Learning untuk mendeteksi penggunaan masker. Program dibuat menggunakan metode CNN dengan arsitektur VGG16Net dan MTCNN untuk face detection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NJ4ryhAKp2X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00779636-e01b-4f68-ccaf-a8b9e84bf5b5"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov  1 20:28:16 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR_DdkBiKsp-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a43efd7-05ca-4a09-ae7b-e489de085c58"
      },
      "source": [
        "# Memeriksa CUDA\n",
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2021 NVIDIA Corporation\n",
            "Built on Sun_Feb_14_21:12:58_PST_2021\n",
            "Cuda compilation tools, release 11.2, V11.2.152\n",
            "Build cuda_11.2.r11.2/compiler.29618528_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3ph4kTgu8UN"
      },
      "source": [
        "## Tahap Awal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ4nspthbm3V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f6a7be1-d36b-4e18-c751-1cc4c96aeb1a"
      },
      "source": [
        "# Melakukan cloning data\n",
        "!git clone https://github.com/Soedirman-Machine-Learning/face-mask-detection.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'face-mask-detection'...\n",
            "remote: Enumerating objects: 4737, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 4737 (delta 19), reused 35 (delta 19), pack-reused 4701\u001b[K\n",
            "Receiving objects: 100% (4737/4737), 469.11 MiB | 31.36 MiB/s, done.\n",
            "Resolving deltas: 100% (119/119), done.\n",
            "Checking out files: 100% (4424/4424), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGAocb4i3q_R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1118b9f-093e-4ea2-efe9-6feceb540f48"
      },
      "source": [
        "# Berpindah ke folder face-mask-detection\n",
        "%cd face-mask-detection/\n",
        "\n",
        "# Memeriksa isi folder face-mask-detection\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/face-mask-detection\n",
            "'aplikasi android'\n",
            " Aplikasi-Android.gif\n",
            "'berkas tugas akhir'\n",
            " dataset\n",
            " face-detector.zip\n",
            " Face_Mask_Detection_MobileNetV2_with_MTCNN.ipynb\n",
            " Face_Mask_Detection_MobileNetV2_with_ResNet10.ipynb\n",
            " Face_Mask_Detection_VGG16Net_with_MTCNN.ipynb\n",
            " Face_Mask_Detection_VGG16Net_with_ResNet10.ipynb\n",
            " Full_Face_Mask_Detection_MobileNetV2.ipynb\n",
            " Full_Face_Mask_Detection_VGG16Net.ipynb\n",
            " logo-md1png.png\n",
            " mask_model.tflite\n",
            " pengujian\n",
            " README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnqMpfEwL_Zp"
      },
      "source": [
        "**Face-detector.zip** merupakan file untuk melakukan pengujian model dengan menggunakan res10_300x300_ssd_iter_140000.caffemodel dan deploy.prototxt untuk mendeteksi bagian wajah"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYnQVobFGH7S",
        "outputId": "1883efc6-8c5a-405a-bc3c-193d7d07e8a5"
      },
      "source": [
        "# Melakukan unzip pada folder face-detector.zip\n",
        "!unzip face-detector.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  face-detector.zip\n",
            "  inflating: deploy.prototxt         \n",
            "  inflating: example_img/ex01.jpg    \n",
            "  inflating: example_img/ex02.jpg    \n",
            "  inflating: example_img/ex03.jpg    \n",
            "  inflating: example_img/ex04.jpg    \n",
            "  inflating: example_img/ex05.jpg    \n",
            "  inflating: example_img/ex06.jpg    \n",
            "  inflating: example_img/ex07.jpg    \n",
            "  inflating: example_img/ex08.jpg    \n",
            "  inflating: example_img/ex09.jpg    \n",
            "  inflating: example_img/ex10.jpg    \n",
            "  inflating: res10_300x300_ssd_iter_140000.caffemodel  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BvjSZ30YhWh"
      },
      "source": [
        "## Mengimpor Libraries yang dibutuhkan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3Za-KOKf-Ot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aee0aced-7d90-4b43-e05b-804cdedee0d9"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import vgg16\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os\n",
        "import itertools\n",
        " \n",
        "# Mengihitung waktu lamanya eksekusi tiap sel di Google Colab\n",
        "!pip install ipython-autotime\n",
        " \n",
        "%load_ext autotime"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (7.9.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 14.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.0.10)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.1.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (57.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipython-autotime) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n",
            "Installing collected packages: jedi, ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.1 jedi-0.18.1\n",
            "time: 423 µs (started: 2022-11-01 20:34:27 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-AQ5m0DgnW1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb602623-ebcc-4077-dc47-2c265b0a0ffd"
      },
      "source": [
        "# Memeriksa Versi TensorFlow\n",
        "print(tf.__version__)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n",
            "time: 2.02 ms (started: 2022-11-01 20:35:10 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU5Fqk2vLELg"
      },
      "source": [
        "## Preprocessing Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D48VICs21pna",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b075efd9-261b-432b-e14c-b4c60b83165f"
      },
      "source": [
        "# Inisialisasi nilai Initial Learning Rate, berapa banyak Epoch pelatihan, dan Batch Size\n",
        "INIT_LR = 1e-4\n",
        "EPOCHS = 30\n",
        "BS = 32\n",
        " \n",
        "# Mengambil gambar dari dataset directory, kemudian inisialisasi data dan class gambar\n",
        "print(\"Menginput gambar...\")\n",
        "imagePaths = list(paths.list_images('dataset'))\n",
        "data = []\n",
        "labels = []\n",
        " \n",
        "# Melakukan perulangan pada image paths\n",
        "for imagePath in imagePaths:\n",
        " \n",
        "    # Mengekstrak class label dari filename\n",
        "    label = imagePath.split(os.path.sep)[-2]\n",
        "    # Memuat input gambar (224x224) dan melakukan proses\n",
        "    image = load_img(imagePath, target_size=(224, 224))\n",
        "    image = img_to_array(image)\n",
        "    image = preprocess_input(image)\n",
        " \n",
        "    # Mengupdate data dan labels lists, berurutan\n",
        "    data.append(image)\n",
        "    labels.append(label)\n",
        " \n",
        "# Mengkonversi data dan label ke dalam NumPy Arrays\n",
        "data = np.array(data, dtype=\"float32\")\n",
        "labels = np.array(labels)\n",
        " \n",
        "# Melakukan one-hot encoding on the labels\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "labels = to_categorical(labels)\n",
        "print(\"Input gambar berhasil\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Menginput gambar...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input gambar berhasil\n",
            "time: 14.1 s (started: 2022-11-01 20:35:16 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aF2vfrgni3tq"
      },
      "source": [
        "### Membuat objek ImageDataGenerator dan Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRBrygye5yvc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d38ac2db-a896-423f-b6b3-05d8afab46a4"
      },
      "source": [
        "# Mempartisi data ke dalam pelatihan dan pengujian ( 75% : 25% )\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
        "    test_size=0.20, stratify=labels, random_state=42)\n",
        " \n",
        "# Membentuk training image generator untuk data augmentation\n",
        "aug = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 909 ms (started: 2022-11-01 20:35:43 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHPD753f5205"
      },
      "source": [
        "## Membuat Model Jaringan CNN yang sudah dipelajari sebelumnya (pre-trained convnets)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaDceTqP6HLr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bce27c4c-ab51-4a5b-d131-af70c83bc017"
      },
      "source": [
        "# Arsitektur jaringan VGG16Net\n",
        "baseModel = tf.keras.applications.VGG16(weights=\"imagenet\", include_top=False,\n",
        "    input_tensor=Input(shape=(224, 224, 3)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 1s 0us/step\n",
            "time: 4.41 s (started: 2022-11-01 20:35:49 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfSLr2q2LWRZ"
      },
      "source": [
        "### Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0U2qYnO6KYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "774a5b75-662f-47e1-aced-dfb501eb7f58"
      },
      "source": [
        "baseModel.trainable = False\n",
        "baseModel.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "time: 69.7 ms (started: 2022-11-01 20:36:02 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENpg9P6Q6SpL"
      },
      "source": [
        "## Tahap Pembuatan Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXEyXB5NTU13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba6832f1-bcc4-4d22-cc69-707a358b6b64"
      },
      "source": [
        "# Membentuk bagian head dari model yang akan ditempatkan pada base model\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(128, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
        " \n",
        "# Menempatkan head model pada base model\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        " \n",
        "# Perulangan pada seluruh base model\n",
        "for layer in baseModel.layers:\n",
        "    layer.trainable = False\n",
        " \n",
        "# Persiapan kompilasi model\n",
        "print(\"Mengkompilasi model...\")\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mengkompilasi model...\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 1, 1, 512)        0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               65664     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,780,610\n",
            "Trainable params: 65,922\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "time: 131 ms (started: 2022-11-01 20:36:08 +00:00)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH42Hp3UWrPs"
      },
      "source": [
        "### Melakukan Pelatihan Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZPSj-se6WdI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "outputId": "d4d6138a-163a-4095-c9db-7b136191ddc4"
      },
      "source": [
        "# Pelatihan model\n",
        "print(\"Training head model...\")\n",
        "H = model.fit(\n",
        "    aug.flow(trainX, trainY, batch_size=BS),\n",
        "    steps_per_epoch=len(trainX) // BS,\n",
        "    validation_data=(testX, testY),\n",
        "    validation_steps=len(testX) // BS,\n",
        "    epochs=EPOCHS)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training head model...\n",
            "Epoch 1/30\n",
            "95/95 [==============================] - 55s 479ms/step - loss: 0.6663 - accuracy: 0.6163 - val_loss: 0.5617 - val_accuracy: 0.9531\n",
            "Epoch 2/30\n",
            "95/95 [==============================] - 37s 391ms/step - loss: 0.5710 - accuracy: 0.7643 - val_loss: 0.4622 - val_accuracy: 0.9413\n",
            "Epoch 3/30\n",
            "95/95 [==============================] - 38s 405ms/step - loss: 0.4703 - accuracy: 0.8754 - val_loss: 0.3776 - val_accuracy: 0.9518\n",
            "Epoch 4/30\n",
            "95/95 [==============================] - 41s 430ms/step - loss: 0.4024 - accuracy: 0.9034 - val_loss: 0.3109 - val_accuracy: 0.9531\n",
            "Epoch 5/30\n",
            "95/95 [==============================] - 39s 406ms/step - loss: 0.3470 - accuracy: 0.9225 - val_loss: 0.2613 - val_accuracy: 0.9583\n",
            "Epoch 6/30\n",
            "95/95 [==============================] - 38s 401ms/step - loss: 0.3018 - accuracy: 0.9258 - val_loss: 0.2231 - val_accuracy: 0.9661\n",
            "Epoch 7/30\n",
            "95/95 [==============================] - 40s 415ms/step - loss: 0.2664 - accuracy: 0.9357 - val_loss: 0.1971 - val_accuracy: 0.9661\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f0ba105336c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     epochs=EPOCHS)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4min 58s (started: 2022-11-01 20:36:18 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxqTwaGi7Wzs"
      },
      "source": [
        "## Menampilkan Grafik Model Hasil Pelatihan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OURpwhV87ac9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "outputId": "843f7672-e296-4c3b-9aed-c50ced908102"
      },
      "source": [
        "N = EPOCHS\n",
        "fig = plt.figure(figsize=(7, 4))\n",
        "fig.set_figheight(10)\n",
        "fig.set_figwidth(15)\n",
        " \n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"],label = \"Training Accuracy\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"],label = \"Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Akurasi\")\n",
        "plt.title(\"Kurva Tingkat Akurasi\", size=15)\n",
        "plt.grid(zorder = 0)\n",
        " \n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"],label = \"Training Loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"],label = \"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Error\")\n",
        "plt.title(\"Kurva Tingkat Error\", size=15)\n",
        "plt.grid(zorder = 0)\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-dae462cdf49a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Training Accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Validation Accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'H' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 174 ms (started: 2022-11-01 20:41:30 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Mqe8nNB7lp8"
      },
      "source": [
        "## Evaluasi Jaringan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLxROO1pg7Em",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a7258a7-d742-4f88-8c27-922554e55c94"
      },
      "source": [
        "# Memeriksa matriks model\n",
        "print(model.metrics_names)\n",
        "# Evaluasi data test\n",
        "print(model.evaluate(x= testX, y = testY))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['loss', 'accuracy']\n",
            "24/24 [==============================] - 6s 263ms/step - loss: 0.1963 - accuracy: 0.9648\n",
            "[0.19630123674869537, 0.9647979140281677]\n",
            "time: 6.76 s (started: 2022-11-01 20:41:42 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySJujhciZvlQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ccaf520-0137-4e14-cc58-327dbf6b29f5"
      },
      "source": [
        "# Menampilkan matriks yang benar dan matriks hasil prediksi\n",
        "# Label yang benar\n",
        "yTrue = np.argmax(testY, axis=1)\n",
        "\n",
        "# Label prediksi\n",
        "YPred = model.predict(testX, batch_size=BS)\n",
        "yPred = np.argmax(YPred, axis=1)\n",
        "\n",
        "print(yTrue)\n",
        "print(yPred)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 4s 151ms/step\n",
            "[0 0 0 1 1 0 1 0 1 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 1 1 1 0 0 1 0 0 0 1 1 0 0\n",
            " 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 1 1 0 1 1\n",
            " 0 1 1 1 0 0 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 0\n",
            " 0 0 1 0 1 0 0 0 1 1 1 0 1 1 0 0 1 0 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1\n",
            " 1 1 0 1 0 1 1 0 0 1 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1 0 1 1 0 0 0\n",
            " 0 0 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 0 0 1 1 0 0 1 1 1\n",
            " 0 0 0 1 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 0 0\n",
            " 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 1 0\n",
            " 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1 1 1 0 0 0 1 0 1 1 0 0 1 0 0 0 1\n",
            " 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1\n",
            " 0 1 1 1 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 1 0 1 1 0 1 1 0 0 0 0 1 0 1\n",
            " 1 1 1 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 1 0 1 1 0 0 1 0 0 1 1 1 1 0 1 1\n",
            " 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 0 1 1 0 1 0 0 1\n",
            " 0 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 1 1 1\n",
            " 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 0 0 0 0 0 1 1 0 1 1\n",
            " 1 0 1 0 0 1 1 1 1 1 0 1 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0\n",
            " 0 0 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1\n",
            " 1 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 0 0 1 0 0 0\n",
            " 1 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0\n",
            " 0 1 1 0 1 0 1 0 1 1 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 1 1\n",
            " 0 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1]\n",
            "[0 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 1 1 1 0 0 1 0 0 0 1 1 0 0\n",
            " 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 1 1 0 1 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1\n",
            " 0 1 1 1 0 0 0 0 0 0 1 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 0 0\n",
            " 0 0 1 0 1 0 0 0 0 1 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1\n",
            " 1 1 1 1 0 1 1 0 0 1 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 0 1 1 1 0 1 1 0 0 0\n",
            " 0 0 1 1 1 0 1 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0 0 0 1 1 0 0 1 1 1\n",
            " 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 1 0 0\n",
            " 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 1 1 1 0 0 0 1 0 1 1 0\n",
            " 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 1 0 1 0 0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 1 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1\n",
            " 0 1 1 1 0 1 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 1 1 0 1 1 0 1 1 0 0 0 0 1 0 1\n",
            " 0 1 1 0 1 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 0 1 1\n",
            " 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 1 1 1 0 0 1 1 0 1 0 0 1\n",
            " 0 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 1 1 1\n",
            " 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 1 1 1 1 0 0 0 0 0 0 1 1 0 1 1\n",
            " 1 0 1 0 0 1 1 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0\n",
            " 0 0 0 1 0 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 1 1 0 0 0 1 1 1 1 1 1\n",
            " 1 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 0 0 1 0 0 0\n",
            " 1 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0\n",
            " 0 1 1 0 1 0 1 0 1 1 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1\n",
            " 0 1 0 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 1 1 1 1 1]\n",
            "time: 4.23 s (started: 2022-11-01 20:41:55 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl0Y-D41imCP"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL_ROzJdh6pm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73477ccf-f42b-4295-def1-0a70dcd535d6"
      },
      "source": [
        "def get_confusion_matrix(yTrue, yPred):\n",
        "    n_classes = len(np.unique(yTrue)) \n",
        "    conf = np.zeros((n_classes, n_classes))\n",
        "    for actual, pred in zip(yTrue, yPred):\n",
        "        conf[int(actual)][int(pred)] += 1\n",
        "    return conf.astype('int')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.62 ms (started: 2022-11-01 20:42:04 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxoC6xxjaCrf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56db394b-c2a1-429c-b773-4d0a34218af3"
      },
      "source": [
        "conf = get_confusion_matrix(yTrue, yPred)\n",
        "conf"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[375,   8],\n",
              "       [ 19, 365]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.18 ms (started: 2022-11-01 20:42:08 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ss9YmprkdirH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "bde12213-497f-44b4-bb0d-1d0025131ad6"
      },
      "source": [
        "classes = [0, 1]\n",
        "# Plot confusion matrix\n",
        "plt.imshow(conf, interpolation='nearest', cmap=plt.cm.Greens)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(classes))\n",
        "plt.xticks(tick_marks, classes)\n",
        "plt.yticks(tick_marks, classes)\n",
        "\n",
        "fmt = 'd'\n",
        "thresh = conf.max() / 2.\n",
        "for i, j in itertools.product(range(conf.shape[0]), range(conf.shape[1])):\n",
        "    plt.text(j, i, format(conf[i, j], fmt),\n",
        "             horizontalalignment=\"center\",\n",
        "             color=\"white\" if conf[i, j] > thresh else \"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.ylabel('Label benar')\n",
        "plt.xlabel('Label Prediksi')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 15.0, 'Label Prediksi')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 464 ms (started: 2022-11-01 20:42:11 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sr58aW7Ui7PD"
      },
      "source": [
        "Analisis mAP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Psuc1y0i_NJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6658efef-22a2-42f8-f345-99551ee2b4ae"
      },
      "source": [
        "# Berdasarkan confusion matrix\n",
        "TP = true_pos = 376\n",
        "TN = true_neg = 375\n",
        "FP = false_pos = 8\n",
        "FN = false_neg = 8"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.19 ms (started: 2022-11-01 20:42:16 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YorxeJVtj0tZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "641363be-0213-499f-e8e1-c4b616a1d342"
      },
      "source": [
        "results = {}\n",
        "\n",
        "# Akurasi\n",
        "metric = \"Akurasi\"\n",
        "results[metric] = (TP + TN) / (TP + TN + FP + FN)\n",
        "print(f\"{metric} = {results[metric]: .3f}\")\n",
        "\n",
        "# Recall\n",
        "metric = \"Recall\"\n",
        "results[metric] = TP / (TP + FN)\n",
        "print(f\"{metric} = {results[metric]: .3f}\")\n",
        "\n",
        "# Presisi\n",
        "metric = \"Presisi\"\n",
        "results[metric] = TP / (TP + FP)\n",
        "print(f\"{metric} = {results[metric]: .3f}\")\n",
        "\n",
        "# Nilai F1\n",
        "metric = \"F1\"\n",
        "results[metric] = 2 / (1 / results[\"Presisi\"] + 1 / results[\"Recall\"])\n",
        "print(f\"{metric} = {results[metric]: .3f}\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Akurasi =  0.979\n",
            "Recall =  0.979\n",
            "Presisi =  0.979\n",
            "F1 =  0.979\n",
            "time: 2.82 ms (started: 2022-11-01 20:42:19 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDPEy5zamOoi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e739bc9d-cec2-4713-b04f-fe14f448c287"
      },
      "source": [
        "# Membuat prediksi dari pengujian\n",
        "predIdxs = model.predict(testX, batch_size=BS)\n",
        " \n",
        "# Untuk setiap gambar dalam set pengujian, kita perlu menemukan indeks label\n",
        "# dengan probabilitas prediksi terbesar\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        " \n",
        "# Menampilkan laporan klasifikasi yang diformat dengan baik\n",
        "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
        "    target_names=lb.classes_))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 3s 150ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   with_mask       0.95      0.98      0.97       383\n",
            "without_mask       0.98      0.95      0.96       384\n",
            "\n",
            "    accuracy                           0.96       767\n",
            "   macro avg       0.97      0.96      0.96       767\n",
            "weighted avg       0.97      0.96      0.96       767\n",
            "\n",
            "time: 3.91 s (started: 2022-11-01 20:42:23 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-H94fpq_E0J"
      },
      "source": [
        "# Pengujian Model dengan MTCNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T0GaCA5_SRw"
      },
      "source": [
        "Model diujikan pada gambar dan secara real-time dengan menggunakan MTCNN yang digunakan untuk mendeteksi wajah."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVWYYLdvZJjP",
        "outputId": "ec945ffe-d9ec-44df-cde9-a8635a99b891"
      },
      "source": [
        "!pip install mtcnn"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mtcnn\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 13.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (2.9.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.21.6)\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.1.1\n",
            "time: 3.83 s (started: 2022-11-01 20:44:34 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nej9QmRT8-DO"
      },
      "source": [
        "## Penggunaan Model pada Gambar\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwPKPee0Qi3h",
        "outputId": "a933549b-96f8-4727-fd1e-873018d41f23"
      },
      "source": [
        "from mtcnn import MTCNN\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 20.6 ms (started: 2022-11-01 20:44:51 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "JkkXJ-MpKKSV",
        "outputId": "fb57bf9b-2136-47b6-9c07-262ccfed9e44"
      },
      "source": [
        "detector = MTCNN()\n",
        "image = cv2.imread('/content/face-mask-detection/example_img/ex5.jpg', cv2.COLOR_BGR2RGB)\n",
        "faces = detector.detect_faces(image)\n",
        "for result in faces:\n",
        "    x, y, w, h = result['box']\n",
        "    x1, y1 = x + w, y + h\n",
        "    \n",
        "    # Ekstrak ROI wajah, konversikan dari BGR ke pemesanan saluran RGB,\n",
        "    # dan mengubah ukurannya menjadi 224x224, dan lalu pre-proses\n",
        "    face = image[y:y1, x:x1]\n",
        "    face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "    face = cv2.resize(face, (224, 224))\n",
        "    face = img_to_array(face)\n",
        "    face = preprocess_input(face)\n",
        "    face = np.expand_dims(face, axis=0)    \n",
        "\n",
        "    # Membaca wajah dengan model\n",
        "    (mask, withoutMask) = model.predict(face)[0]\n",
        "\n",
        "    # Menggunakan masker hijau, tidak bermasker merah\n",
        "    label = \"Bermasker\" if mask > withoutMask else \"Tidak Bermasker\"\n",
        "    color = (0, 255, 0) if label == \"Bermasker\" else (0, 0, 255)\n",
        "\n",
        "\t\t# Probabilitas hasil deteksi\n",
        "    label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
        "\n",
        "    # Menampilkan hasil dengan label dan kotak\n",
        "    cv2.putText(image, label, (x, y - 10),\n",
        "    cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
        "    cv2.rectangle(image, (x, y), (x1, y1), color, 2)\n",
        "\n",
        "# Menampilkan output\n",
        "cv2_imshow(image)\n",
        "cv2.waitKey(0)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidImage",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidImage\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-c811ad1c72df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMTCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/face-mask-detection/example_img/ex5.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'box'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/mtcnn/mtcnn.py\u001b[0m in \u001b[0;36mdetect_faces\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \"\"\"\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mInvalidImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image not valid.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidImage\u001b[0m: Image not valid."
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 557 ms (started: 2022-11-01 20:44:58 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njXIK_L3dVXx"
      },
      "source": [
        "## Pengujian Deteksi Perframe Capture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wdWN4xy-Nxd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7494d92e-aa34-4370-a7b4-5aa9a15e5973"
      },
      "source": [
        "# Mengimport lib\n",
        "from mtcnn import MTCNN\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "from imutils.video import VideoStream\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import time\n",
        "import cv2\n",
        "import os\n",
        "import base64\n",
        "import html\n",
        "import io\n",
        "import time"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 7.47 ms (started: 2022-11-01 20:46:30 +00:00)\n"
          ]
        }
      ]
    }
  ]
}